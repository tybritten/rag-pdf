{
  "autoscaling": false,
  "input": {
    "pfs": {
      "glob": "/",
      "name": "data",
      "repo": "embed-docs",
      "branch": "tg"
    }
  },
  "pipeline": {
    "name": "gui",
    "project": {
      "name": "default"
    }
  },
  "service": {
    "externalPort": 32080,
    "internalPort": 8501,
    "type": "NodePort"
  },
  "transform": {
    "cmd": [
      "/bin/bash",
      "-C"
    ],
    "env": {
      "DOCUMENT_REPO": "documents",
      "PACH_PROXY_EXTERNAL_URL_BASE": "http://rag.psdc.lan:30080",
      "PYTHON_UNBUFFERED": "1"
    },
    "image": "vmtyler/pdk:gui-v0.4.2c",
    "stdin": [
      "streamlit run gui.py -- --path-to-db /pfs/data --path-to-chat-model http://llama3.mlis.svc.cluster.local/v1 --model \"/mnt/models/Meta-Llama-3.1-8B-Instruct/\" --emb-model-path http://embed.mlis.svc.cluster.local/v1 --cutoff 0.4 --streaming"
    ]
  }
}
